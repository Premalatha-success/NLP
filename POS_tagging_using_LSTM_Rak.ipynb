{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H6RZUm0p4wYJ",
    "outputId": "a598c97a-63ce-4c39-a1d0-595975c7c506"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TWi96z-8SyX0"
   },
   "outputs": [],
   "source": [
    "# Initialize the random number generator\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "# Ignore the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OKVkkLaLdPGU"
   },
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JK0ZRJoxhrFe"
   },
   "source": [
    "As we are using google colab, we need to mount the google drive to load the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lDTL5oRkmJK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# IMPORT DATA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('ner_dataset.csv', encoding='latin1')\n",
    "data = data.fillna(method=\"ffill\") # Deal with N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrZ4pIhxkmJP"
   },
   "outputs": [],
   "source": [
    "tags = list(set(data[\"POS\"].values)) # Read POS values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 752
    },
    "colab_type": "code",
    "id": "y5dLVpx-kmJS",
    "outputId": "bde09fb2-6258-4263-9697-86a80eff2a79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VBD',\n",
       " 'RBR',\n",
       " 'WRB',\n",
       " 'TO',\n",
       " 'NNPS',\n",
       " 'CD',\n",
       " '``',\n",
       " 'IN',\n",
       " 'JJR',\n",
       " 'DT',\n",
       " 'WP',\n",
       " 'LRB',\n",
       " 'NNP',\n",
       " 'PRP$',\n",
       " 'UH',\n",
       " 'JJS',\n",
       " 'POS',\n",
       " 'VB',\n",
       " ':',\n",
       " ',',\n",
       " 'RB',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " 'WP$',\n",
       " '$',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'FW',\n",
       " 'WDT',\n",
       " 'JJ',\n",
       " 'EX',\n",
       " 'RRB',\n",
       " 'RP',\n",
       " 'VBN',\n",
       " ';',\n",
       " 'CC',\n",
       " 'VBZ',\n",
       " 'PDT',\n",
       " 'VBP',\n",
       " 'VBG',\n",
       " 'MD',\n",
       " 'RBS']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags # List of possible POS values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kla7rPZ4kmJV"
   },
   "outputs": [],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"DUMMY\") # Add a dummy word to pad sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0quKyRPkmJY"
   },
   "outputs": [],
   "source": [
    "# Code to read sentences\n",
    "\n",
    "class ReadSentences(object): \n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5RMj10qkmJa"
   },
   "outputs": [],
   "source": [
    "sentences = ReadSentences(data).sentences # Read all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7CEvxwAkmJe"
   },
   "outputs": [],
   "source": [
    "# Convert words and tags into numbers\n",
    "word2id = {w: i for i, w in enumerate(words)}\n",
    "tag2id = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BHnxkCxTkmJh"
   },
   "outputs": [],
   "source": [
    "# Prepare input and output data\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "max_len = 50\n",
    "X = [[word2id[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=len(words)-1)\n",
    "y = [[tag2id[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2id[\".\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-R4K9GikmJn"
   },
   "outputs": [],
   "source": [
    "# Convert output to one-hot bit\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=len(tags)) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "oAur07mkkmJq",
    "outputId": "cc135f05-6e40-4e32-badb-63e1b1c2ad68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNDkmkAkkmJw"
   },
   "outputs": [],
   "source": [
    "# Training and test split by sentences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PHFx7nojkmJy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cc1Ss7aVkmJ0"
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(max_len,)) # Input layer\n",
    "model = Embedding(input_dim=len(words), output_dim=50, input_length=max_len)(input) # Word embedding layer\n",
    "model = Dropout(0.1)(model) # Dropout\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model) # Bi-directional LSTM layer\n",
    "out = TimeDistributed(Dense(len(tags), activation=\"softmax\"))(model)  # softmax output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LDIws8lAkmJ3"
   },
   "outputs": [],
   "source": [
    "model = Model(input, out) # Complete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-j6oKch0kmJ5"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) # Compile with an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "QATrRFNAkmJ8",
    "outputId": "3c8fd630-372f-4200-8654-726da39ea2b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1080/1080 [==============================] - 290s 248ms/step - loss: 0.5768 - accuracy: 0.8395 - val_loss: 0.1374 - val_accuracy: 0.9607\n",
      "Epoch 2/3\n",
      "1080/1080 [==============================] - 246s 228ms/step - loss: 0.0897 - accuracy: 0.9754 - val_loss: 0.0707 - val_accuracy: 0.9795\n",
      "Epoch 3/3\n",
      "1080/1080 [==============================] - 286s 265ms/step - loss: 0.0523 - accuracy: 0.9855 - val_loss: 0.0595 - val_accuracy: 0.9827\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=3, validation_split=0.1, verbose=1) # Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 892
    },
    "colab_type": "code",
    "id": "JZI4x1DgkmKA",
    "outputId": "5ee87eb8-e73d-4d94-b7ff-4487d6dbe5ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Mr.                  -- NNP\n",
      "Netanyahu            -- NNP\n",
      "was                  -- VBD\n",
      "elected              -- VBN\n",
      "to                   -- TO\n",
      "lead                 -- VB\n",
      "Likud                -- NNP\n",
      "last                 -- JJ\n",
      "month                -- NN\n",
      ",                    -- ,\n",
      "after                -- IN\n",
      "Mr.                  -- NNP\n",
      "Sharon               -- NNP\n",
      "left                 -- VBD\n",
      "the                  -- DT\n",
      "party                -- NN\n",
      ".                    -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n"
     ]
    }
   ],
   "source": [
    "# Demo test on one sample. See how it is mostly correct, but not 100%\n",
    "\n",
    "i = 1213 # Some test sentence sample\n",
    "p = model.predict(np.array([X_te[i]])) # Predict on it\n",
    "p = np.argmax(p, axis=-1) # Map softmax back to a POS index\n",
    "for w, pred in zip(X_te[i], p[0]): # for every word in the sentence\n",
    "    print(\"{:20} -- {}\".format(words[w], tags[pred])) # Print word and tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "l7FYeWwmqp8u",
    "outputId": "71668428-bd97-4545-b4e0-ca042060b2bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBTSn305kmKD"
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "sentence = nltk.word_tokenize('That was a nice jump')\n",
    "X_Samp = pad_sequences(maxlen=max_len, sequences=[[word2id[word] for word in sentence]], padding=\"post\", value=len(words)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 892
    },
    "colab_type": "code",
    "id": "qlLPSYujkmKH",
    "outputId": "a4a16f45-3818-43ad-d52a-01bc07f1e3f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n",
      "That                 -- DT\n",
      "was                  -- VBD\n",
      "a                    -- DT\n",
      "nice                 -- JJ\n",
      "jump                 -- NN\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n",
      "DUMMY                -- .\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(np.array([X_Samp[0]])) # Predict on it\n",
    "p = np.argmax(p, axis=-1) # Map softmax back to a POS index\n",
    "for w, pred in zip(X_Samp[0], p[0]): # for every word in the sentence\n",
    "    print(\"{:20} -- {}\".format(words[w], tags[pred])) # Print word and tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWVnTDL-HnFg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "POS tagging using LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
